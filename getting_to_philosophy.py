# -*- coding: utf-8 -*-
"""Getting to Philosophy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GjzzslGbvHjRTMkg8o0kGuQOtXn7flF7
"""

from requests import get
from bs4 import BeautifulSoup
# RANDOM_PAGE_URL = 'https://en.wikipedia.org/wiki/Special:Random'
# RANDOM_PAGE_URL = 'https://en.wikipedia.org/wiki/Object'
visted = []
def philsofy():
    url = 'https://en.wikipedia.org/wiki/Special:Random'
    while True:
        response = get(url)
        soup = BeautifulSoup(response.text, 'html.parser')
        title = soup.title.text;
        
        if title not in visted:
          visted.append(title)
        else:
          url = 'https://en.wikipedia.org/wiki/Special:Random'
          print("Repeated Title")
          continue
          
        print("title=", title)
        
        if title == "Philosophy - Wikipedia":
            print('Philosophy=',url) 
            break
            
        FindFirstLink = find_first_link(soup)
        
        if(FindFirstLink == 'e'):
          url = 'https://en.wikipedia.org/wiki/Special:Random'
          print("Pages without Links")
          continue
        
        if(FindFirstLink.attrs['href'][:5] == "https"):
          url = FindFirstLink.attrs['href']
        else:
          url = "https://en.wikipedia.org" + FindFirstLink.attrs['href']
          
        


def find_first_link(page):
    body = page.find("div", {"class": "mw-parser-output"})
    paragraphs = (body.select('p'));
    links = []
    for p in paragraphs:
        newLinks = p.findChildren('a', {"title": True} , recursive=False)
        links = links + newLinks
        
    if(len(links) == 0):
      body = page.find("div", {"class": "mw-parser-output"})
      paragraphs = (body.select('a'));
      links = []
      for p in paragraphs:
          if(p.attrs['href'][:5] == "/wiki"):
            newLinks = [p]
            links = links + newLinks
      return links[0]
    else:
      links = filter_dead_links(links)
      if(len(links) == 0):
        return 'e'
      else:
        return links[0]


def filter_dead_links(links):
    arr = []
    for link in links:
      if link.has_attr('class'):
        if link.attrs['class'] != 'new' and link.attrs['href'][:5] != "https":
           arr.append(link)
      else:
         arr.append(link)
    return arr



philsofy()